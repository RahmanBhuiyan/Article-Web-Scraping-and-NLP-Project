# Article Web Scraping & text preprocessing in nlp 

This project aims to perform Natural Language Processing (NLP) tasks using the NLTK library. The objectives of the project include:

1. Data Extraction (Web Scraping): The project will involve scraping article text from the provided URLs using web scraping techniques.
2. Exploratory Data Analysis: Perform exploratory data analysis on the extracted text using NLTK to gain insights and understand the data.
3. Variable Extraction: Calculate the values of various linguistic variables using NLTK and NLP techniques. The variables to be extracted include:
    - Positive Score
    - Negative Score
    - Polarity Score
    - Subjectivity Score
    - Average Sentence Length
    - Percentage of Complex Words
    - Fog Index
    - Average Number of Words per Sentence
    - Complex Word Count
    - Word Count
    - Syllables per Word
    - Personal Pronouns
    - Average Word Length

## Web Scraping

The first step of the project will be to scrape the article text from the provided URLs using web scraping techniques. This may involve using libraries like BeautifulSoup or Scrapy to extract the relevant content from each webpage.

## Exploratory Data Analysis

Once the article text is extracted, NLTK will be used for exploratory data analysis. NLTK provides various tools and methods for text preprocessing, tokenization, and visualization. These techniques will be applied to gain insights into the data, such as word frequency analysis, part-of-speech tagging, and sentiment analysis.

## Variable Extraction

After the exploratory analysis, NLTK will be used to extract the values of the specified linguistic variables from the article text. NLTK provides functions and modules for tasks like sentiment analysis, text classification, and readability analysis, which will be utilized to calculate the values of each variable.

The specific methods and algorithms used will depend on the requirements and nature of each variable. For example, sentiment analysis can be performed using NLTK's built-in sentiment lexicons, while readability analysis can be done using NLTK's formulas or external tools like the Flesch-Kincaid Grade Level or Fog Index.

## Dataset

The dataset for this project will be obtained by scraping article text from the provided URLs. Each article will be treated as a separate data instance for analysis.

